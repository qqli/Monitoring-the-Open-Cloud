#summary
##DARGOS: A highly adaptable and saclable monitoring architecture for mutli-tenant Clouds

In the paper ‘DARGOS: A highly adaptable and scalable monitoring architecture for multi-tenant clouds’, the author claims that resource needs of applications depends not only on service types, but also on cloud’s dynamic conditions. The author also claims that incorrect estimations of cloud may lead to misleading results. So they proposed Distributed Architecture for Resource management and monitoring in clouds(DARGOS), a monitoring architecture based on data-centric DDS push-based publish/subscribe paradigm, and also combines automatic discovery, filtering capabilities, asynchronous event handling. DARGOS use NMAs(Node monitoring agent) to collect data from local nodes and publish them to subscribed nodes. NSAs(Node Supervisor Agent) are used to receive, store and maintain data collected from NMAs. NMAs are installed in every monitored host, and each tenant has an NSA that receive monitoring information(Haven’t figure out where to install NSAs and the databases). In an OpenStack environment, NMAs are installed in every compute node and nova controller. They also created a DARGOS scheduler, which use the monitoring data from NSA, for allocating resources dynamically.
Because each tenant is a subscriber that subscribes the monitoring data, DARGOS can provide suitable data for tenants based on their use of the cloud as well as administrators who want to know information of the whole cloud. I still need to check if DARGOS has a single database or each NSA has its own database. The network traffic is reduced significantly, for DARGOS only send data to related tenants(subscribers). For the network evaluation in OpenStack environment,  it got good results, but the experiment only contain one NSA and three NMAs. Moreover, OpenStack depends on AMQP and mySQL for basic communications except from monitoring. The measurements may not be correct just extract DARGOS network usage and compare it with OpenStack network usage (Maybe I am wrong because I do not know how to measure the traffic of only OpenStack monitoring function).


##MonPaaS: An Adaptive Monitoring Platform as a Service for Cloud Computing Infrastructures and Services

MonPaaS is said to be an adaptive monitoring platform that can monitor virtual and physical resources as well as keeping a mapping between virtual and physical resources. It can also provide independent monitoring for providers and users. Furthermore, it allows users to configure and customize the resources and services they would like to monitor. MonPaaS listens to OpenStack message queue and get the messages of physical as well as virtual resources change information. 

##Cloud monitoring: A survey

The paper “Cloud monitoring: A survey” suggests the advantages of cloud computing for both economical and technical aspects. For economical aspect, users can invest lower capitals and have more flexibility in resources and SLAs. For technical aspect, cloud computing can easily realize scalability in data and resources. The author then proposes the usage for cloud monitoring, such as capacity and resource planning for service developers who can use the monitored information to determine the estimated workload and also determine the resource to be purchased from the cloud. Monitoring the cloud can provide the availability information for cloud physical as well as virtual resources. The monitored data can be used for analyzing for energy efficiency improvement studies. Cloud monitoring can also be used for SLA management, billing, troubleshooting, performance management and security management as the author claims. The paper also introduces three basic concepts of cloud monitoring: (1)the seven layers for monitoring, (2)abstraction levels which includes high-level and low level monitoring (3) tests and metrics which lists the metrics that are monitored in detail. After emphasizing the significance and components of cloud monitoring, this paper lists several characteristics that cloud monitoring desires, scalability, elasticity, adaptability, timeliness to name a few. Then it lists a set of commercial cloud monitoring tools and open source monitoring tools that are in use now with some description and characteristic information for each of the monitoring tool. In the last part, the paper analyses current issues and some directions for future cloud monitoring. 


First of all, this paper has a detailed and organized part for the motivation of cloud monitoring, which can guide us for the purpose of our project. It also provides us with a list of metrics that can be monitored in its basic concept part, which can add to our list of measurements. The properties part can provide us with a guide when we want to choose our monitoring tools or compare between monitoring tools. It can also give us some direction when we work on our cloud monitoring project. For example, we need to think what can we do to realize scalability of our cloud monitoring project, as is the same with other properties. In the end, it points out some directions that our research can work towards, such as cross-layer monitoring (virtual and physical resource mapping), federated clouds and energy monitoring. 

##A scalable architecture for real-time monitoring of large information systems

The paper, “A scalable architecture for real-time monitoring of large information systems”, mostly deals with the scalability issue for cloud monitoring and comes up with method to avoid single points of failure to increase fault tolerance. First, it claims that in order to realize large scale system monitoring, we must move from centralize monitoring systems to distributed systems. Two projects, Ganglia and Astrolabe are proposed as the related work. The the paper describes the design of its project. Two ways are proposed in this paper to scale up the monitoring system. The first one is to decrease and compress data resource, by filtering resource data stream on the monitored nodes and doing live compression. The second one is to use map-reduce in storage end, which it says to group write operations and batch to secondary storage. This paper also introduces two methods to avoid single points of failure. The first one is to do replications and deploy solutions using software that can be easily replicated. The second solution is to have multiple collection agents. 

There are several parts that I like about this paper. First, the output from the monitored node will be sent to a program that can do sanity checks, such as missing value check, value out of range check and sequence of null values check. If a check is failed, the resource data will be tagged as invalid for debugging purposes. In this way, we can increase the correctness of monitored data. Second, it uses a index to represent the name of the desired metrics, which can make the resource data smaller. Third, data received are decoded and send to two types of storage, the first one for real-time plotting, and the second one for analyzing. It can also be deployed in several collection agents and each agent has its own database. For our purpose, because we need to analyze data for the whole cluster, it is good to have a database for each cluster, which can realize a certain level of distribution. 

## Summary : Toward an Architecture for Monitoring Private Clouds

It first illustrates some cloud computing background, such as cloud computing service models (*aaS), cloud computing deployment models (public, private, hybrid) and cloud computing standards. The article proposes a monitoring tool, PCMONS. For the physical part, it uses node information gatherer to get each node’s data and then send the data to cluster data integrator in each cluster. Cluster data integrators will send the data to monitoring data integrator and store the data to a database. Configuration generator is used to generate config files from database that store hardware data and then send the file to monitoring tool that can visualize the data.  For virtual part, a VM monitor is used to monitor all VMs and send to monitoring tool, in this case Nagios. Monitoring tool can store the data and also visualize it. 

This paper provides a centralized prototype for cloud monitoring. Basically it separates virtual and physical environments in monitoring and also provides a way to store historical data. But going through so many levels may take up a lot of bandwidth in the cloud that may be a problem for scalability. 

##Summary A Runtime Model Based Monitoring Approach for Cloud

In the paper “A runtime Model Based Monitoring Approach for Cloud”, the author proposes a model (RMCM), which provides information of a running cloud and also claims to have a balance between runtime overhead and monitoring capacity. The paper claims that they will provide the three types of roles—cloud operators, service providers and end users—with three different views. Cloud operators have the view of the whole cloud to inspect the running status of it; service developers has the view of showing the status of their applications and the tenants of their applications; end users have the view of multiple services to choose from. Besides, this paper also proposes four entities to be monitored—infrastructure, middleware, application, and interaction behavior. This model is an agent based model—each virtual machine has a monitoring agent.  

## Summary GMonE:

The paper provides two ways to study monitoring, the first one is to study the monitored components (cloud monitoring level) and the second one is to study the intention of the monitoring information (cloud monitoring vision). It divides the cloud architecture to four levels: server, being the lowest level, is considered as cloud’s physical system; infrastructure, platform, and applications are considered cloud’s virtual system. This paper focuses mainly on monitoring virtual systems. This paper also considers two roles in cloud—client and cloud service provider. For each of the virtual level (infrastructure, platform and software), this paper provides an aspect of what to monitor for both client and service provider. The paper claims to have an architecture that has a layer,monitor access, that provides access to both virtual and physical systems. It also has a data gathering layer for storing all data from monitoring access layer. GMonE is a monitoring system that uses the architecture they propose. The monitoring component is GMonEMon, which is a module that can monitor all four layers and get the operational data. GMonEDB is the monitoring manager which stores the information generated by GMonEMon and stores to different databases(Different clients have different databases). They also provide a library, GMonEAccess, which provides user easy access to the data.

## Achieving cost-efficient, data-intensive computing in the cloud

This paper focuses on understanding the scaling behavior of virtualized cloud network and storage resources. They evaluate the performance using MapReduce experiment. Unlike the traditional MapReduce, which stores intermediate data to local disk, they store the data to memory, which can save time and eliminates the networking bottleneck possibilities. The paper compares the total cost for the same task implemented in different machines, which show us results that the vm with the highest hourly rate actually cost the least.

Reading this paper further confirms the purpose of our project. Admin users can use the data exposed to them to have a better and more appropriate pricing model, such as taking energy consumption into account. Users can use the data exposed to them to choose VMs that are suitable to them. Furthermore, they claim to have hardware limitations, for example, they cannot choose so many large VMs and they must change to another region for other experiments. If they have the hardware information at the first time, they will have a better choice on where to perform their experiment and not waste resource and money.


## Using Data Transformations for low-latency time series analysis

This paper states that monitoring generates huge amount of time series data, and it is very difficult to achieve near real-time response. So they develop a data transformation mechanism to summarize time series data. They use downsampling to extract data, for example, get one-tenth of the original data by downsampling. Then they store this data to a new table for later use. In this way, they can achieve less latency because the data size is only one-tenth of the original. The trade off is this data is less accurate, and also this will take up more storage. 

The database schema looks very much like the ones we use in influxdb. We can store hourly data or daily data generated by downsampling from the original data to different tables (series). When people do queries, they can use these tables that have much less latency. They can also use the original data to form their own analysis, but with higher latency. 

